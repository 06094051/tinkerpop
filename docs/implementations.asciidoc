[[implementations]]
Implementations
===============

image::gremlin-racecar.png[width=325]

[[vendor-requirements]]
Vendor Requirements
-------------------

image:tinkerpop-enabled.png[width=125,float=left] At the core of TinkerPop3 is a Java8 API. The implementation of this core API and its validation via the `gremlin-test` suite is all that is required of a vendor wishing to provide a TinkerPop3-enabled graph engine. Once a vendor has a valid implementation, then all the applications provided by TinkerPop (e.g. Gremlin Console, Gremlin Server, etc.) and 3rd-party developers (e.g. Gremlin-Scale, Gremlin-JS, etc.) will integrate properly with their graph engine. Finally, please feel free to use the logo on the left to promote your TinkerPop3 implementation.

Implementing Gremlin-Core
~~~~~~~~~~~~~~~~~~~~~~~~~

The classes that a vendor should focus on implemented are itemized below. Please feel free to study the TinkerGraph (in-memory OLTP and OLAP in `tinkergraph-gremlin`), Neo4jGraph (OTLP w/ transactions in `neo4j-gremlin`) and/or GiraphGraph (OLAP in `giraph-gremlin`) implementations for ideas and patterns.

. Online Transactional Processing Graph Systems (*OLTP*)
 .. Structure API: `Graph`, `Element`, `Vertex`, `Edge`, `Property` and `Transaction` (if transactions are supported).
 .. Process API: a single `Step` that states how to yield vertices or edges from a `Graph` (i.e. `Graph.V()` and `Graph.E()`).
. Online Analytics Processing Graph Systems (*OLAP*)
 .. Everything required of OTLP is required of OLAP (but not vice versa).
 .. GraphComputer API: `GraphComputer`, `Messenger`, `SideEffects`.

A collection of implementation notes:

* Please ensure your `Graph` implementation is named as `XXXGraph` (e.g. TinkerGraph, Neo4jGraph, GiraphGraph, etc.).
* Use `StringHelper` to ensuring that the `toString()` representation of classes are consistent with other implementations.
* Ensure that your implementation's `Features` (Graph, Vertex, etc.) are correct so that test cases handle particulars accordingly.

[[validating-with-gremlin-test]]
Validating with Gremlin-Test
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

[source,xml]
<dependency>
  <groupId>com.tinkerpop</groupId>
  <artifactId>gremlin-test</artifactId>
  <version>x.y.z</version>
</dependency>

The operational semantics of any OLTP or OLAP implementation are validated by `gremlin-test`. Please provide the following test cases with your implementation, where `XXX` below denotes the name of your graph implementation (e.g. TinkerGraph, Neo4jGraph, GiraphGraph, etc.).

[source,java]
----
// Structure API tests
@RunWith(StructureStandardSuite.class)
@StructureStandardSuite.GraphProviderClass(provider = XXXGraphProvider.class, graph = XXXGraph.class)
public class XXXStructureStandardTest {}

@RunWith(StructurePerformanceSuite.class)
@StructurePerformanceSuite.GraphProviderClass(provider = XXXGraphProvider.class, graph = XXXGraph.class)
public class XXXStructurePerformanceTest {}

// Process API tests
@RunWith(ProcessComputerSuite.class)
@ProcessComputerSuite.GraphProviderClass(provider = XXXGraphProvider.class, graph = XXXGraph.class)
public class XXXProcessComputerTest {}

@RunWith(ProcessStandardSuite.class)
@ProcessStandardSuite.GraphProviderClass(provider = XXXGraphProvider.class, graph = XXXGraph.class)
public class XXXProcessStandardTest {}
----

The only test-class that requires any code investment is the `XXXGraphProvider.class`. Neo4j's implementation is provided below for reference.

[source,java]
----
public class Neo4jGraphProvider extends AbstractGraphProvider {
    @Override
    public Map<String, Object> getBaseConfiguration(final String graphName) {
	// this is what is passed into XXX.open()
        return new HashMap<String, Object>() {{
            put("gremlin.graph", Neo4jGraph.class.getName());
            put("gremlin.neo4j.directory", getWorkingDirectory() + File.separator + graphName);
        }};
    }

    @Override
    public void clear(final Graph g, final Configuration configuration) throws Exception {
        if (null != g) {
            if (g.getFeatures().graph().supportsTransactions())
                g.tx().rollback();
            g.close();
        }
        if (configuration.containsKey("gremlin.neo4j.directory")) {
            // this is a non-in-memory configuration so blow away the directory
            final File graphDirectory = new File(configuration.getString("gremlin.neo4j.directory"));
            deleteDirectory(graphDirectory);
        }
    }
}
---- 

Finally, specify the test suites that will be supported by the `Graph` implementation using the `@Graph.OptIn` annotation.  See the `TinkerGraph` implementation below as an example:

[source,java]
----
@Graph.OptIn(Graph.OptIn.SUITE_STRUCTURE_STANDARD)
@Graph.OptIn(Graph.OptIn.SUITE_STRUCTURE_PERFORMANCE)
@Graph.OptIn(Graph.OptIn.SUITE_PROCESS_STANDARD)
@Graph.OptIn(Graph.OptIn.SUITE_PROCESS_COMPUTER)
public class TinkerGraph implements Graph, Serializable {
----

Only include annotations for the suites the implementation will support.  Note that implementing the suite, but not specifying the appropriate annotation will prevent the suite from running (an obvious error message will appear in this case when running the mis-configured suite).

There are times when there may be a specific test in the suite that the implementation cannot support (despite the features it implements) or should not otherwise be executed.  It is possible for implementers to "opt-out" of a test by using the `@Graph.OptOut` annotation.  The following is an example of this annotation usage as taken from `GiraphGraph`: 

[source, java]
----
@Graph.OptIn(Graph.OptIn.SUITE_PROCESS_STANDARD)
@Graph.OptIn(Graph.OptIn.SUITE_PROCESS_COMPUTER)
@Graph.OptOut(
        test = "com.tinkerpop.gremlin.process.graph.step.map.MatchTest$JavaMatchTest",
        method = "g_V_matchXa_hasXname_GarciaX__a_inXwrittenByX_b__a_inXsungByX_bX",
        reason = "Giraph-Gremlin is OLAP-oriented and for OLTP operations, linear-scan joins are required. This particular tests takes many minutes to execute.")
@Graph.OptOut(
        test = "com.tinkerpop.gremlin.process.graph.step.map.MatchTest$JavaMatchTest",
        method = "g_V_matchXa_inXsungByX_b__a_inXsungByX_c__b_outXwrittenByX_d__c_outXwrittenByX_e__d_hasXname_George_HarisonX__e_hasXname_Bob_MarleyXX",
        reason = "Giraph-Gremlin is OLAP-oriented and for OLTP operations, linear-scan joins are required. This particular tests takes many minutes to execute.")
@Graph.OptOut(
        test = "com.tinkerpop.gremlin.process.computer.GraphComputerTest",
        method = "shouldNotAllowBadSideEffectKeys",
        reason = "Giraph does a hard kill on failure and stops threads which stops test cases. Exception handling semantics are correct though.")
@Graph.OptOut(
        test = "com.tinkerpop.gremlin.process.computer.GraphComputerTest",
        method = "shouldRequireRegisteringSideEffectKeys",
        reason = "Giraph does a hard kill on failure and stops threads which stops test cases. Exception handling semantics are correct though.")
public class GiraphGraph implements Graph, Serializable {
----

These annotations help provide users a level of transparency into test suite compliance (via the xref:describe-graph[describeGraph()] utility function). It also allows implementers to have a lot of flexibility in terms of how they wish to support TinkerPop.  For example, maybe there is a single test case that prevents an implementer from claiming support of a `Feature`.  The implementer could choose to either not support the `Feature` or support it but "opt-out" of the test with a "reason" as to why so that users understand the limitation.

Accessibility via GremlinPlugin
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

image:gremlin-plugin.png[width=100,float=left] The applications distributed with TinkerPop3 do not distribute with any vendor implementations besides TinkerGraph. If your implementation is stored in a Maven repository (e.g. Maven Central Repository), then it is best to provide a `GremlinPlugin` implementation so the respective jars can be downloaded according and when required by the user. Neo4j's GremlinPlugin is provided below for reference.

[source,java]
----
public class Neo4jGremlinPlugin implements GremlinPlugin {

    private static final String IMPORT = "import ";
    private static final String DOT_STAR = ".*";

    private static final Set<String> IMPORTS = new HashSet<String>() {{
        add(IMPORT + Neo4jGraph.class.getPackage().getName() + DOT_STAR);
    }};

    @Override
    public String getName() {
        return "neo4j";
    }

    @Override
    public void pluginTo(final PluginAcceptor pluginAcceptor) {
        pluginAcceptor.addImports(IMPORTS);
    }
}
---- 

With the above plugin implementations, users can now download respective binaries for Gremlin Console, Gremlin Server, etc.

[source,groovy]
gremlin> g = Neo4jGraph.open('/tmp/neo4j')
No such property: Neo4jGraph for class: groovysh_evaluate
Display stack trace? [yN]
gremlin> :install com.tinkerpop neo4j-gremlin x.y.z
==>loaded: [com.tinkerpop, neo4j-gremlin, â€¦]
gremlin> :plugin use neo4j
==>neo4j activated
gremlin> g = Neo4jGraph.open('/tmp/neo4j')
==>neo4jgraph[EmbeddedGraphDatabase [/tmp/neo4j]]

In-Depth Implementations
~~~~~~~~~~~~~~~~~~~~~~~~

image:gremlin-painting.png[width=200,float=right] The vendor implementation details presented thus far are minimum requirements necessary to yield a valid TinkerPop3 implementation. However, there are other areas that a vendor can tweak to provide an implementation more optimized for their underlying graph engine. Typical areas of focus include:

* Traversal Strategies: A <<traversalstrategy,TraversalStrategy>> can be used to alter a traversal prior to its execution. A typical example is converting a pattern of `g.V().has('name','marko')` into a global index lookup for all vertices with name "marko". In this way, a `O(|V|)` lookup becomes an `O(log(|V|))`. Please review `TinkerGraphStepStrategy` for ideas.
* Step Implementations: Every <<graph-traversal-steps,step>> is ultimately referenced by the `GraphTraversal` interface. It is possible to extend `GraphTraversal` to use a vendor-specific step implementation.


[[tinkergraph-gremlin]]
TinkerGraph-Gremlin
-------------------

[source,xml]
----
<dependency>
   <groupId>com.tinkerpop</groupId>
   <artifactId>tinkergraph-gremlin</artifactId>
   <version>x.y.z</version>
</dependency>
----

image:tinkerpop-character.png[width=100,float=left] TinkerGraph is a single machine, in-memory, non-transactional graph engine that provides both OLTP and OLAP functionality. It is deployed with TinkerPop3 and serves as the reference implementation for other vendors to study in order to understand the semantics of the various methods of the TinkerPop3 API. Constructing a simple graph in Java8 is presented below.

[source,java]
Graph g = TinkerGraph.open();
Vertex marko = g.addVertex("name","marko","age",29);
Vertex lop = g.addVertex("name","lop","lang","java");
marko.addEdge("created",lop,"weight",0.6d);

The above graph creates two vertices named "marko" and "lop" and connects them via a created-edge with a weight=0.6 property. Next, the graph can be queried as such.

[source,java]
g.V().has("name","marko").out("created").value("name")

The `g.V().has("name","marko")` part of the query can be executed in two ways.

 * A linear scan of all vertices filtering out those vertices that don't have the name "marko"
 * A `O(log(|V|))` index lookup for all vertices with the name "marko"

Given the initial graph construction in the first code block, no index was defined and thus, a linear scan is executed. However, if the graph was constructed as such, then an index lookup would be used.

[source,java]
Graph g = TinkerGraph.open();
g.createIndex("name",Vertex.class)

The runtimes for a vertex lookup by property is provided below for both no-index and indexed version of TinkerGraph over the Grateful Dead graph.

[source,groovy]
gremlin> g = TinkerGraph.open()
==>tinkergraph[vertices:0 edges:0]
gremlin> g.loadGraphML('data/grateful-dead.xml')
==>null
gremlin> clock(1000){g.V.has('name','Garcia').next()}
==>0.11787599999999974  <1>
gremlin> g = TinkerGraph.open()
==>tinkergraph[vertices:0 edges:0]
gremlin> g.createIndex('name',Vertex.class)
==>null
gremlin> g.loadGraphML('data/grateful-dead.xml')
==>null
gremlin> clock(1000){g.V.has('name','Garcia').next()}
==>0.03508100000000018 <2>

<1> Average runtime of 1000 vertex lookups when no `name`-index is defined.
<2> Average runtime of 1000 vertex lookups when a `name`-index is defined.

IMPORTANT: Each graph vendor will have different mechanism by which indices and schemas are defined. TinkerPop3 does not require any conformance in this area. In TinkerGraph, the only definitions are around indices. With other vendors, property value types, indices, edge labels, etc. may be required to be defined _a priori_ to adding data to the graph.

NOTE: TinkerGraph is distributed with Gremlin Server and is therefore automatically available to it for configuration.

[[neo4j-gremlin]]
Neo4j-Gremlin
-------------

[source,xml]
----
<dependency>
   <groupId>com.tinkerpop</groupId>
   <artifactId>neo4j-gremlin</artifactId>
   <version>x.y.z</version>
</dependency>
----

image:neotechnology-logo.png[width=150,float=left] link:http://neotechnology.com[Neo Technology] are the developers of the OLTP-based link:http://neo4j.org[Neo4j graph database].

CAUTION: Unless under a commercial agreement with Neo Technology, Neo4j is licensed as link:http://en.wikipedia.org/wiki/Affero_General_Public_License[AGPL]. Thus, `gremlin-neo4j` (source and binaries) are licensed as such due to their dependency on the Neo4j library. Note that neither the <<gremlin-console,Gremlin Console>> nor <<gremlin-server,Gremlin Server>> distribute with the Neo4j binaries. To access the Neo4j binaries, use the `:install` command to download binaries from link:http://search.maven.org/[Maven Central Repository].

[source,groovy]
----
gremlin> :install com.tinkerpop neo4j-gremlin x.y.z
==>loaded: [com.tinkerpop, neo4j-gremlin, x.y.z]
gremlin> :plugin use neo4j
==>neo4j activated
gremlin> g = Neo4jGraph.open('/tmp/neo4j')
==>neo4jgraph[EmbeddedGraphDatabase [/tmp/neo4j]]
----

For those leveraging Neo4j High Availability, configure `Neo4jGraph` for "HA mode" by setting the `gremlin.neo4j.ha` flag to `true` in the `Configuration` object passed to `Neo4jGraph.open()`.  Note that when the flag is set (by default it is `false`), the `Neo4jGraph` instance expects HA configuration settings to be present.  As with embedded Neo4j, HA configuration keys should be prefixed with `gremlin.neo4j.conf`.  Please consult Neo4j documentation for more information on link:http://docs.neo4j.org/chunked/stable/ha.html[High Availability] configuration.

TIP: To host Neo4j in Gremlin Server, the dependencies must first be "installed" or otherwise copied to the Gremlin Server path.  The automated method for doing this would be to execute `bin/gremlin-server.sh -i com.tinkerpop neo4j-gremlin x.y.z`.

Cypher
~~~~~~

Neo4j are the creators of the graph pattern-match query language link:http://www.neo4j.org/learn/cypher[Cypher]. It is possible to leverage Cypher from within Gremlin by using the `Neo4jGraph.cypher()` graph traversal method.

[source,groovy]
gremlin> g = Neo4jGraph.open('/tmp/neo4j')
==>neo4jgraph[EmbeddedGraphDatabase [/tmp/neo4j]]
gremlin> g.loadKryo('data/tinkerpop-classic.gio')
==>null
gremlin> g.cypher('MATCH (a {name:"marko"}) RETURN a')
==>[a:v[0]]
gremlin> g.cypher('MATCH (a {name:"marko"}) RETURN a').select('a').out('knows').name
==>vadas
==>josh
gremlin> g.cypher("MATCH (n{name:'marko'})-[:knows]->(m) RETURN m").select('m').id.fold.cypher("MATCH (m)-[:created]->(n) WHERE id(m) in {start} RETURN n").select("n").name
==>lop
==>ripple

Thus, like <<match-step,`match()`>> in Gremlin, it is possible to do a declarative pattern match and then move back into imperative Gremlin.  The last query presented above shows that the `cypher` step can be used at the start of a traversal or in the middle.  When used in the middle of a traversal, the result from the previous step becomes bound to an argument named `start`, which can then be used in the Cypher query as an argument.  In the example above, the vertex identifiers from the Cypher query that starts the traversal are collected with `fold` and which in turn produces a single Cypher query using those identifiers.  Without `fold`, the second Cypher query would have executed once for each identifier in the traversal and the Cypher would have had to have changed to something like: `MATCH (m)-[:created]->(n) WHERE id(m) = {start} RETURN n' (where the `IN` is replaced by `=`).

IMPORTANT: For those developers using <<gremlin-server,Gremlin Server>> against Neo4j, it is possible to do Cypher queries by simply placing the Cypher string in `g.cypher(...)` before submission to the server.

[[giraph-gremlin]]
Giraph-Gremlin
--------------

[source,xml]
----
<dependency>
   <groupId>com.tinkerpop</groupId>
   <artifactId>giraph-gremlin</artifactId>
   <version>x.y.z</version>
</dependency>
----

image:giraph-logo.png[width=100,float=left] link:http://giraph.apache.org[Giraph] is an Apache Foundation project focused on OLAP-based graph processing. Giraph makes use of the distributed graph computing paradigm made popular by Google's Pregel. In Giraph, developers write "vertex programs" that get executed at each vertex in parallel. These programs communicate with one another in a bulk synchronous parallel (BSP) manner. This model aligns with TinkerPop3's `GraphComputer` API. TinkerPop3 provides an implementation of `GraphComputer` that works for Giraph called `GiraphGraphComputer`. Moreover, with TinkerPop3's <<mapreduce,MapReduce>>-framework, the standard Giraph/Pregel model is extended to support an arbitrary number of MapReduce phases to aggregate and yield results from the graph. Finally, note that `GiraphGraph` also supports read-only OLTP operations (though via linear scans of HDFS serializations).

IMPORTANT: image:hadoop-logo-notext.png[width=100,float=left] This section assumes that the user has a Hadoop 1.x cluster functioning. For more information on getting started with Hadoop, please see their link:http://hadoop.apache.org/docs/r1.2.1/single_node_setup.html[Single Node Setup] tutorial. Moreover, it is advisable that the reader also familiarize themselves with Giraph as well via their link:http://giraph.apache.org/quick_start.html[Getting Started] page.

Installing Giraph-Gremlin
~~~~~~~~~~~~~~~~~~~~~~~~~

To the `.bash_profile` file, add the following environmental variable (of course, be sure the directories are respective of the local machine locations). The `GIRAPH_GREMLIN_LIBS` folder is the location of all the Giraph-Gremlin jars. It is possible to place developer jars into this directory for loading into the Hadoop job's classpath.

[source,shell]
export GIRAPH_GREMLIN_LIBS=/usr/local/gremlin-console/ext/giraph-gremlin/

If using the <<gremlin-console,Gremlin Console>>, it is important to install the Giraph-Gremlin plugin.

[source,text]
----
$ bin/gremlin.sh

         \,,,/
         (o o)
-----oOOo-(3)-oOOo-----
plugin activated: server
plugin activated: utilities
gremlin> :install com.tinkerpop giraph-gremlin x.y.z
==>loaded: [com.tinkerpop, giraph-gremlin, x.y.z] - restart the console to use [giraph]
gremlin> :q
$ bin/gremlin.sh

         \,,,/
         (o o)
-----oOOo-(3)-oOOo-----
plugin activated: server
plugin activated: utilities
gremlin> :plugin use giraph
==>giraph activated
gremlin> 
----

IMPORTANT: Be sure that the link:http://www.slf4j.org/[SLF4J] of Hadoop matches that of Giraph or else there will be conflicts. Simply copy the following jars to the `lib/` of the machines in the Hadoop cluster: `slf4j-api-x.y.z.jar` and `slf4j-log4j12-x.y.z.jar`.

WARNING: Giraph uses a large number of Hadoop counters. The default for Hadoop is 120. In `mapred-site.xml` it is possible to increase the limit it via the `mapreduce.job.counters.limit` property. A good value to use is 1000. This is a cluster-wide property so be sure to restart the cluster after updating.

Properties Files
~~~~~~~~~~~~~~~~

The `GiraphGraphComputer` makes use of a properties file much like any other `GraphComputer`. However, given the relationship to Hadoop which is property heavy, it is important to look at a particular properties file. The properties file below is located at `conf/giraph-kryo.properties'.

[source,text]
gremlin.graph=com.tinkerpop.gremlin.giraph.structure.GiraphGraph
gremlin.inputLocation=tinkerpop-classic-vertices.gio
giraph.vertexInputFormatClass=com.tinkerpop.gremlin.giraph.structure.io.kryo.KryoVertexInputFormat
gremlin.outputLocation=output
giraph.vertexOutputFormatClass=com.tinkerpop.gremlin.giraph.structure.io.kryo.KryoVertexOutputFormat
gremlin.sideEffectOutputFormatClass=org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat
gremlin.vertexProgram=com.tinkerpop.gremlin.process.computer.traversal.TraversalVertexProgram
gremlin.traversalVertexProgram.traversalSupplierClass=com.tinkerpop.gremlin.giraph.process.graph.example.TraversalSupplier1
gremlin.jarsInDistributedCache=true
gremlin.deriveComputerSideEffects=false
giraph.minWorkers=2
giraph.maxWorkers=2

A review of the properties above are presented in the table below.

[width="100%",cols="2,10",options="header"]
|=========================================================
|Property |Description
|gremlin.graph |The class of the graph to construct using GraphFactory
|gremlin.inputLocation |The location of the input file(s) for Giraph to read the graph from.
|giraph.vertexInputFormatClass |The format that the graph input file(s) are represented in.
|gremlin.outputLocation |The location to write the computed Giraph graph to.
|giraph.vertexOutputFormatClass |The format that the output file(s) should be represented in.
|gremlin.sideEffectOutputFormatClass |The format of any resultant GraphComputer SideEffects.
|gremlin.vertexProgram |The `VertexProgram` to distribute to all vertices in the `GiraphGraph`
|gremlin.traversalVertexProgram.traversalSupplierClass |For `TraversalVertexProgram`, the location of the Gremlin traversal to use (if not using Gremlin Console).
|gremlin.jarsInDistributedCache |Whether to upload the Giraph-Gremlin jars to Hadoop's distributed cache (necessary if jars are not on machines' classpaths).
|gremlin.deriveComputerSideEffects |Whether or not `SideEffects` are yielded (requires an extra MapReduce job if true).
|giraph.minWorkers |The minimum number of parallel workers to execute the vertices of the graph.
|giraph.maxWorkers |The maximum number of parallel workers to execute the vertices of the graph.
|=========================================================

IMPORTANT: The maximum number of workers can be no larger than the number of map-slots in the Hadoop cluster minus 1. For example, if the Hadoop cluster has 4 map slots, then `giraph.maxWorkers` can not be larger than 3. One map-slot is reserved for the master compute node and all other slots can be allocated as workers to execute the VertexPrograms on the vertices of the graph.

The above properties file states:

	The location of the graph is tinkerpop-classic-vertices.gio. Interpret that file using KryoVertexInputFormat. When evaluating the graph over the Giraph/Hadoop cluster, execute the TraversalVertexProgram on all vertices of the graph using the traversal defined in TraversalSupplier1. Write the computed on GiraphGraph to output/ using the KryoVertexOutputFormat. Use 2 workers (thus, 3 map-slots) to execute the job.
 
Along with the properties above, the numerous link:http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/core-default.xml[Hadoop specific properties] can be added as needed to tune and parameterize the executed Giraph-Gremlin job on the respective Hadoop cluster.

OLTP Giraph-Gremlin
~~~~~~~~~~~~~~~~~~~

image:giraph-pipes.png[width=110,float=left] It is possible to execute OLTP operations over Giraph-Gremlin. However, realize that the underlying HDFS files are typically not random access and thus, to retrieve a vertex, a linear scan is required. It is possible to create input formats that leverage Hadoop Map files.

CAUTION: OLTP operations on `GiraphGraph` are not efficient. They require linear scans to execute and are unreasonable for large graphs. In such large graph situations, make use of <<traversalvertexprogram,TraversalVertexProgram>> which is the OLAP implementation of the Gremlin language.

[source,text]
gremlin> hdfs.copyFromLocal('data/tinkerpop-classic-vertices.gio', 'tinkerpop-classic-vertices.gio')
==>null
gremlin> hdfs.ls()
==>rw-r--r-- marko supergroup 891 tinkerpop-classic-vertices.gio
gremlin> g = GraphFactory.open('../../../giraph-gremlin/conf/giraph-kryo.properties')  // be conscious of where giraph-kryo.properties is
==>giraphgraph[kryovertexinputformat->kryovertexoutputformat]
gremlin> g.V.count()
==>6
gremlin> g.V.out.out.name
==>ripple
==>lop
gremlin> g.V.groupBy{it.value('name')[1]}{it.value('name')}.next()
==>a=[marko, vadas]
==>e=[peter]
==>i=[ripple]
==>o=[lop, josh]

NOTE: When executing a <<vertexprogram,`VertexProgram`> via `g.compute().program(...).submit()`, it is important that `g` is created with `GiraphGraph.open()`.  

OLAP Giraph-Gremlin
~~~~~~~~~~~~~~~~~~~

image:giraph-furnace.png[width=110,float=left] Giraph-Gremlin was designed to execute OLAP operations via `GraphComputer`. The OLTP examples presented above are reproduced below, but using `TraversalVertexProgram` for the execution of the Gremlin traversal.

IMPORTANT: When using Giraph-Gremlin OLAP from the Gremlin Console, the only Gremlin language subset supported is Gremlin-Groovy.

[source,text]
gremlin> :remote connect giraph ../../../giraph-gremlin/conf/giraph-kryo.properties
==>giraphgraph[kryovertexinputformat->kryovertexoutputformat]
gremlin> :> g.V.count()
INFO  com.tinkerpop.gremlin.giraph.process.computer.GiraphGraphComputer  - GiraphGremlin: TraversalVertexProgram[GiraphGraphStep, CountStep]
INFO  org.apache.hadoop.mapred.JobClient  - Running job: job_201407281259_0037
INFO  org.apache.hadoop.mapred.JobClient  -  map 0% reduce 0%
...
INFO  com.tinkerpop.gremlin.giraph.process.computer.GiraphGraphComputer  - GiraphGremlin: CountCapMapReduce
INFO  org.apache.hadoop.mapred.JobClient  - Running job: job_201407281259_0038
INFO  org.apache.hadoop.mapred.JobClient  -  map 0% reduce 0%
...
==>6
gremlin> :> g.V.out.out.name
INFO  com.tinkerpop.gremlin.giraph.process.computer.GiraphGraphComputer  - GiraphGremlin: TraversalVertexProgram[GiraphGraphStep, VertexStep(OUT), VertexStep(OUT), ElementValueStep(name)]
INFO  org.apache.hadoop.mapred.JobClient  - Running job: job_201407281259_0031
INFO  org.apache.hadoop.mapred.JobClient  -  map 0% reduce 0%
...
INFO  com.tinkerpop.gremlin.giraph.process.computer.GiraphGraphComputer  - GiraphGremlin: TraversalResultMapReduce
INFO  org.apache.hadoop.mapred.JobClient  - Running job: job_201407281259_0032
INFO  org.apache.hadoop.mapred.JobClient  -  map 0% reduce 0%
...
==>ripple
==>lop
gremlin> :> g.V.groupBy{it.value('name')[1]}{it.value('name')}.as('a')
INFO  com.tinkerpop.gremlin.giraph.process.computer.GiraphGraphComputer  - GiraphGremlin: TraversalVertexProgram[GiraphGraphStep, GroupByStep@a]
INFO  org.apache.hadoop.mapred.JobClient  - Running job: job_201407281259_0039
INFO  org.apache.hadoop.mapred.JobClient  -  map 0% reduce 0%
...
INFO  com.tinkerpop.gremlin.giraph.process.computer.GiraphGraphComputer  - GiraphGremlin: GroupByMapReduce
INFO  org.apache.hadoop.mapred.JobClient  - Running job: job_201407281259_0040
INFO  org.apache.hadoop.mapred.JobClient  -  map 0% reduce 0%
...
==>[a:[marko, vadas], e:[peter], i:[ripple], o:[lop, josh]]
gremlin> result
==>result[giraphgraph[kryovertexinputformat->kryovertexoutputformat],sideEffects[size:1]]
gremlin> result.sideEffects.runtime
==>20356
gremlin> result.sideEffects.keys()
==>a
gremlin> result.sideEffects.a
==>Optional[{a=[marko, vadas], e=[peter], i=[ripple], o=[lop, josh]}]
gremlin> result.sideEffects.a.get()
==>a=[marko, vadas]
==>e=[peter]
==>i=[ripple]
==>o=[lop, josh]

NOTE: Distributed graph computations on cluster-sized graphs can yield an enormous number of results. To be safe, Giraph-Gremlin only returns up to 20 results to the console (with, of course, all the results being available in HDFS). If more results are desired, simply leverage `_l`.

The results of the graph traversal are stored in HDFS accessible via `hdfs`.

[source,text]
gremlin> hdfs.ls()
==>rwxr-xr-x marko supergroup 0 (D) output
==>rw-r--r-- marko supergroup 891 tinkerpop-classic-vertices.gio
gremlin> hdfs.ls('output')
==>rwxr-xr-x marko supergroup 0 (D) a
==>rwxr-xr-x marko supergroup 0 (D) ~g
gremlin> hdfs.ls('output/a')
==>rw-r--r-- marko supergroup 0 _SUCCESS
==>rwxr-xr-x marko supergroup 0 (D) _logs
==>rw-r--r-- marko supergroup 332 part-r-00000
gremlin> hdfs.head('output/a',KryoWritable.class)
==>[a, [marko, vadas]]
==>[e, [peter]]
==>[i, [ripple]]
==>[o, [lop, josh]]

A list of the HDFS methods available are itemized below. Note that these methods are also available for the 'local' variable:

[width="100%",cols="13,10",options="header"]
|=========================================================
| Method| Description
|hdfs.ls(String path)| List the contents of the supplied directory. 
|hdfs.cp(String from, String to)| Copy the specified path to the specified path.
|hdfs.exists(String path)| Whether the specified path exists.
|hdfs.rm(String path)| Remove the specified path.
|hdfs.rmr(String path)| Remove the specified path and its contents recurssively.
|hdfs.copyToLocal(String from, String to)| Copy the specified HDFS path to the specified local path.
|hdfs.copyFromLocal(String from, String to)| Copy the specified local path to the specified HDFS path.
|hdfs.mergeToLocal(String from, String to)| Merge the files in path to the specified local path.
|hdfs.head(String path)| Text display the data in the path.
|hdfs.head(String path, long lineCount)| Text display only the first `totalKeyValues` in the path.
|hdfs.head(String path, long totalKeyValues, Class<Writable> writableClass)| Display the path interpreting the key values as respective writable.
|=========================================================


The `TraversalSupplier1` class mentioned in the `giraph-kryo.properties` file is distributed with Giraph-Gremlin. It declares what Gremlin-Java traversal to execute on the loaded `GiraphGraph`. This is the means why which traversals can be programmatically executed in Giraph-Gremlin.

[source,java]
----
// gremlin.traversalVertexProgram.traversalSupplierClass=com.tinkerpop.gremlin.giraph.process.graph.example.TraversalSupplier1

public class TraversalSupplier1 implements SSupplier<Traversal> {
    public Traversal get() {
        return GiraphGraph.open().V().out().out().value("name");
    }
}
----

A Command Line Example
~~~~~~~~~~~~~~~~~~~~~~

image::pagerank-logo.png[width=300]

The classic link:http://en.wikipedia.org/wiki/PageRank[PageRank] centrality algorithm can be executed over TinkerPop classic from the command line.

NOTE: The extension `ldjson` in `giraph-graphson.properties` refers to link:http://en.wikipedia.org/wiki/Line_Delimited_JSON[line-delimitated JSON] which is the file format used by `GraphSONWriter` when writing an link:http://en.wikipedia.org/wiki/Adjacency_list[adjacency list] representation of a graph.

[source,text]
$ hadoop fs -copyFromLocal data/tinkerpop-classic-vertices.ldjson tinkerpop-classic-vertices.ldjson
$ hadoop fs -ls
Found 2 items
-rw-r--r--   1 marko supergroup        891 2014-07-28 13:00 /user/marko/tinkerpop-classic-vertices.gio
-rw-r--r--   1 marko supergroup       2356 2014-07-28 13:00 /user/marko/tinkerpop-classic-vertices.ldjson
$ hadoop jar target/giraph-gremlin-x.y.z-job.jar com.tinkerpop.gremlin.giraph.process.computer.GiraphGraphComputer conf/giraph-graphson.properties
14/07/29 12:08:27 INFO computer.GiraphGraphComputer: GiraphGremlin: com.tinkerpop.gremlin.process.computer.ranking.pagerank.PageRankVertexProgram
14/07/29 12:08:28 INFO mapred.JobClient: Running job: job_201407281259_0041
14/07/29 12:08:29 INFO mapred.JobClient:  map 0% reduce 0%
14/07/29 12:08:51 INFO mapred.JobClient:  map 66% reduce 0%
14/07/29 12:08:52 INFO mapred.JobClient:  map 100% reduce 0%
14/07/29 12:08:54 INFO mapred.JobClient: Job complete: job_201407281259_0041
14/07/29 12:08:54 INFO mapred.JobClient: Counters: 57
14/07/29 12:08:54 INFO mapred.JobClient:   Map-Reduce Framework
14/07/29 12:08:54 INFO mapred.JobClient:     Spilled Records=0
14/07/29 12:08:54 INFO mapred.JobClient:     Map input records=3
14/07/29 12:08:54 INFO mapred.JobClient:     SPLIT_RAW_BYTES=132
14/07/29 12:08:54 INFO mapred.JobClient:     Map output records=0
14/07/29 12:08:54 INFO mapred.JobClient:     Total committed heap usage (bytes)=347602944
14/07/29 12:08:54 INFO mapred.JobClient:   Giraph Timers
14/07/29 12:08:54 INFO mapred.JobClient:     Shutdown (milliseconds)=385
14/07/29 12:08:54 INFO mapred.JobClient:     Superstep 1 (milliseconds)=89
14/07/29 12:08:54 INFO mapred.JobClient:     Superstep 23 (milliseconds)=28
14/07/29 12:08:54 INFO mapred.JobClient:     Input superstep (milliseconds)=1127
14/07/29 12:08:54 INFO mapred.JobClient:     Superstep 27 (milliseconds)=30
14/07/29 12:08:54 INFO mapred.JobClient:     Superstep 10 (milliseconds)=34
14/07/29 12:08:54 INFO mapred.JobClient:     Superstep 5 (milliseconds)=43
14/07/29 12:08:54 INFO mapred.JobClient:     Superstep 22 (milliseconds)=31
14/07/29 12:08:54 INFO mapred.JobClient:     Superstep 14 (milliseconds)=35
14/07/29 12:08:54 INFO mapred.JobClient:     Total (milliseconds)=4023
14/07/29 12:08:54 INFO mapred.JobClient:     Superstep 2 (milliseconds)=50
14/07/29 12:08:54 INFO mapred.JobClient:     Superstep 18 (milliseconds)=29
14/07/29 12:08:54 INFO mapred.JobClient:     Superstep 11 (milliseconds)=35
14/07/29 12:08:54 INFO mapred.JobClient:     Superstep 24 (milliseconds)=32
14/07/29 12:08:54 INFO mapred.JobClient:     Superstep 28 (milliseconds)=32
14/07/29 12:08:54 INFO mapred.JobClient:     Superstep 15 (milliseconds)=34
14/07/29 12:08:54 INFO mapred.JobClient:     Superstep 6 (milliseconds)=37
14/07/29 12:08:54 INFO mapred.JobClient:     Superstep 19 (milliseconds)=31
14/07/29 12:08:54 INFO mapred.JobClient:     Superstep 25 (milliseconds)=27
14/07/29 12:08:54 INFO mapred.JobClient:     Superstep 8 (milliseconds)=33
14/07/29 12:08:54 INFO mapred.JobClient:     Superstep 12 (milliseconds)=44
14/07/29 12:08:54 INFO mapred.JobClient:     Superstep 20 (milliseconds)=31
14/07/29 12:08:54 INFO mapred.JobClient:     Superstep 16 (milliseconds)=31
14/07/29 12:08:54 INFO mapred.JobClient:     Superstep 9 (milliseconds)=36
14/07/29 12:08:54 INFO mapred.JobClient:     Setup (milliseconds)=1119
14/07/29 12:08:54 INFO mapred.JobClient:     Superstep 3 (milliseconds)=50
14/07/29 12:08:54 INFO mapred.JobClient:     Superstep 7 (milliseconds)=38
14/07/29 12:08:54 INFO mapred.JobClient:     Superstep 13 (milliseconds)=36
14/07/29 12:08:54 INFO mapred.JobClient:     Superstep 29 (milliseconds)=37
14/07/29 12:08:54 INFO mapred.JobClient:     Superstep 26 (milliseconds)=40
14/07/29 12:08:54 INFO mapred.JobClient:     Superstep 0 (milliseconds)=293
14/07/29 12:08:54 INFO mapred.JobClient:     Superstep 21 (milliseconds)=46
14/07/29 12:08:54 INFO mapred.JobClient:     Superstep 17 (milliseconds)=32
14/07/29 12:08:54 INFO mapred.JobClient:     Superstep 4 (milliseconds)=39
14/07/29 12:08:54 INFO mapred.JobClient:   File Input Format Counters
14/07/29 12:08:54 INFO mapred.JobClient:     Bytes Read=0
14/07/29 12:08:54 INFO mapred.JobClient:   Giraph Stats
14/07/29 12:08:54 INFO mapred.JobClient:     Aggregate finished vertices=0
14/07/29 12:08:54 INFO mapred.JobClient:     Aggregate edges=0
14/07/29 12:08:54 INFO mapred.JobClient:     Sent messages=6
14/07/29 12:08:54 INFO mapred.JobClient:     Current workers=2
14/07/29 12:08:54 INFO mapred.JobClient:     Last checkpointed superstep=0
14/07/29 12:08:54 INFO mapred.JobClient:     Current master task partition=0
14/07/29 12:08:54 INFO mapred.JobClient:     Superstep=30
14/07/29 12:08:54 INFO mapred.JobClient:     Aggregate vertices=6
14/07/29 12:08:54 INFO mapred.JobClient:   FileSystemCounters
14/07/29 12:08:54 INFO mapred.JobClient:     HDFS_BYTES_READ=2488
14/07/29 12:08:54 INFO mapred.JobClient:     FILE_BYTES_WRITTEN=250470
14/07/29 12:08:54 INFO mapred.JobClient:     HDFS_BYTES_WRITTEN=2719
14/07/29 12:08:54 INFO mapred.JobClient:   Job Counters
14/07/29 12:08:54 INFO mapred.JobClient:     Launched map tasks=3
14/07/29 12:08:54 INFO mapred.JobClient:     SLOTS_MILLIS_REDUCES=0
14/07/29 12:08:54 INFO mapred.JobClient:     Total time spent by all reduces waiting after reserving slots (ms)=0
14/07/29 12:08:54 INFO mapred.JobClient:     SLOTS_MILLIS_MAPS=31907
14/07/29 12:08:54 INFO mapred.JobClient:     Total time spent by all maps waiting after reserving slots (ms)=0
14/07/29 12:08:54 INFO mapred.JobClient:   File Output Format Counters
14/07/29 12:08:54 INFO mapred.JobClient:     Bytes Written=0
$ hadoop fs -cat output/~g/*
{"inE":[],"outE":[{"inV":3,"inVLabel":"vertex","outVLabel":"vertex","id":9,"label":"created","type":"edge","outV":1,"hiddens":{},"properties":{"weight":0.4}},{"inV":2,"inVLabel":"vertex","outVLabel":"vertex","id":7,"label":"knows","type":"edge","outV":1,"hiddens":{},"properties":{"weight":0.5}},{"inV":4,"inVLabel":"vertex","outVLabel":"vertex","id":8,"label":"knows","type":"edge","outV":1,"hiddens":{},"properties":{"weight":1.0}}],"id":1,"label":"vertex","type":"vertex","hiddens":{"gremlin.pageRank":0.15000000000000002,"gremlin.edgeCount":3.0},"properties":{"name":"marko","age":29}}
{"inE":[{"inV":5,"inVLabel":"vertex","outVLabel":"vertex","id":10,"label":"created","type":"edge","outV":4,"hiddens":{},"properties":{"weight":1.0}}],"outE":[],"id":5,"label":"vertex","type":"vertex","hiddens":{"gremlin.pageRank":0.23181250000000003,"gremlin.edgeCount":0.0},"properties":{"name":"ripple","lang":"java"}}
{"inE":[{"inV":3,"inVLabel":"vertex","outVLabel":"vertex","id":9,"label":"created","type":"edge","outV":1,"hiddens":{},"properties":{"weight":0.4}},{"inV":3,"inVLabel":"vertex","outVLabel":"vertex","id":11,"label":"created","type":"edge","outV":4,"hiddens":{},"properties":{"weight":0.4}},{"inV":3,"inVLabel":"vertex","outVLabel":"vertex","id":12,"label":"created","type":"edge","outV":6,"hiddens":{},"properties":{"weight":0.2}}],"outE":[],"id":3,"label":"vertex","type":"vertex","hiddens":{"gremlin.pageRank":0.4018125,"gremlin.edgeCount":0.0},"properties":{"name":"lop","lang":"java"}}
{"inE":[{"inV":4,"inVLabel":"vertex","outVLabel":"vertex","id":8,"label":"knows","type":"edge","outV":1,"hiddens":{},"properties":{"weight":1.0}}],"outE":[{"inV":5,"inVLabel":"vertex","outVLabel":"vertex","id":10,"label":"created","type":"edge","outV":4,"hiddens":{},"properties":{"weight":1.0}},{"inV":3,"inVLabel":"vertex","outVLabel":"vertex","id":11,"label":"created","type":"edge","outV":4,"hiddens":{},"properties":{"weight":0.4}}],"id":4,"label":"vertex","type":"vertex","hiddens":{"gremlin.pageRank":0.19250000000000003,"gremlin.edgeCount":2.0},"properties":{"name":"josh","age":32}}
{"inE":[{"inV":2,"inVLabel":"vertex","outVLabel":"vertex","id":7,"label":"knows","type":"edge","outV":1,"hiddens":{},"properties":{"weight":0.5}}],"outE":[],"id":2,"label":"vertex","type":"vertex","hiddens":{"gremlin.pageRank":0.19250000000000003,"gremlin.edgeCount":0.0},"properties":{"name":"vadas","age":27}}
{"inE":[],"outE":[{"inV":3,"inVLabel":"vertex","outVLabel":"vertex","id":12,"label":"created","type":"edge","outV":6,"hiddens":{},"properties":{"weight":0.2}}],"id":6,"label":"vertex","type":"vertex","hiddens":{"gremlin.pageRank":0.15000000000000002,"gremlin.edgeCount":1.0},"properties":{"name":"peter","age":35}}

Vertex 4 ("josh") is isolated below:

[source,js]
{
 "inE":[
  {"inV":4,"inVLabel":"vertex","outVLabel":"vertex","id":8,
    "label":"knows","type":"edge","outV":1,"hiddens":{},"properties":{"weight":1.0}}
 ],
 "outE":[
  {"inV":5,"inVLabel":"vertex","outVLabel":"vertex","id":10,
    "label":"created","type":"edge","outV":4,"hiddens":{},"properties":{"weight":1.0}},
  {"inV":3,"inVLabel":"vertex","outVLabel":"vertex","id":11,
    "label":"created","type":"edge","outV":4,"hiddens":{},"properties":{"weight":0.4}}
 ],
 "id":4,
 "label":"vertex",
 "type":"vertex",
 "hiddens":{
  "gremlin.pageRank":0.19250000000000003,
  "gremlin.edgeCount":2.0
 },
 "properties":{
  "name":"josh",
  "age":32
 }
}
